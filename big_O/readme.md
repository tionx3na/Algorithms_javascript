# BIG-O NOTATION

BIG-O notation (asymptotic notation) is the language that we use for talking about how long an algorithm takes to run. We can use BIG-O notation to compare two algorithms to determine which is better when it comes to scale regardless of the performance differences of different systems.

In mathematical terms, BIG-O notation describes the limiting behaviour of a function when the argument tends towards a particular value or infinity.


## BIG-O Rules

Rules for simplyfying Big-O notations, 

- Worst Case (Always take the worst case scenerio)
- Remove Constants (Ignore the constants in the notation since it's insignificant)
- Different terms for inputs
- Drop Non Dominants